# Spring Cloud Stream on RabbitMQ Performance Tests

## Overview

This project contains scripts to test performances of a
[Spring Cloud Stream](https://cloud.spring.io/spring-cloud-stream/) application
using the [RabbitMQ](http://www.rabbitmq.com/) binder.
The application is a simple Spring Cloud Stream sink.

There are 3 roles in this benchmark:
 * broker: it runs the RabbitMQ broker
 * publisher: it publishes messages to the broker
 * consumer: it consumes messages from the broker
 
Each role is supposed to run on a dedicated machine, but it's technically possible to run all
roles on a single machine.

## Installation

### Broker

 * clone this repository: `git clone https://github.com/rabbitmq/scdf-performance.git`
 * go to the project repository: `cd scdf-performance/scst/scst-rabbitmq-performance`
 * install the broker: `./install-broker.sh`
 * edit the `.env` to configure the username and the password (the user will be created
 automatically in the next step). Don't use the `guest` user if your applications
 are supposed to connect from an external machine.
 * configure the broker: `./configure-broker.sh`
 
RabbitMQ management plugin is then available on port 80 (through HAProxy).
 
Warnings:
 * the `guest` user isn't deleted automatically. You should delete it in any security
 sensitive environment
 * the management plugin and HAProxy don't use HTTPS. You should configure HTTPS in any
 security sensitive environment. 
 
### Consumer

 * clone this repository: `git clone https://github.com/rabbitmq/scdf-performance.git`
 * go to the project repository: `cd scdf-performance/scst/scst-rabbitmq-performance`
 * install the JDK: `./install-java.sh`
 * install PerfTest: `./install-perf-test.sh`
 * build the Spring Cloud Stream application: `./mvnw clean package`
 
### Publisher

 * clone this repository: `git clone https://github.com/rabbitmq/scdf-performance.git`
 * go to the project repository: `cd scdf-performance/scst/scst-rabbitmq-performance`
 * install the JDK: `./install-java.sh`
 * install PerfTest: `./install-perf-test.sh`

### Typical installation

 * broker: 16 vCPUs, 104 GB RAM, SSD if using persistent messages
 * consumer: 4 vCPUs, 15 GB RAM
 * publisher: 4 vCPUs, 15 GB RAM

## Usage

There are different supported workloads.

### Partition

This workload uses Spring Cloud Stream native partition support. This translates to using
1 dedicated queue per partition. Note only 10 partitions at most are supported.

#### Broker

 * edit `.env` to configure the number of partitions
 * configure the AMQP resources: `./configure-broker.sh`
 * make sure the queue are empty: `./purge-queues-partition.sh`

#### Consumer

 * edit `.env` to configure the number of partitions, connection parameters, and
 any consumer-related option (e.g. prefetch count)
 * start the Spring Cloud Stream application instances: `./start-scst-partition.sh`
 * make sure all the instances are connected to the broker by e.g. looking at the
 management plugin (all instances can take some time to load when several partitions are used)
 * when you're done, stop the application instances: `./stop-all-scst.sh`

You can get consuming throughput numbers from the management plugin or from
`partition-{partition-number}.txt` files generated by the application instances.

This workload supports also plain PerfTest consumers (can be good to have a basis to compare against).
To use PerfTest consumers:
 * edit `.env` to configure the number of partitions, connection parameters, and
 any consumer-related option (e.g. prefetch count)
 * start the PerfTest consumer instances: `./start-perf-test-consumer-partition.sh`
 * make sure all the instances are connected to the broker by e.g. looking at the
 management plugin
 * when you're done, stop the PertTest instances: `./stop-all-perf-test.sh`  

You can get consuming throughput numbers from the management plugin or from
`perf-test-consumer-partition-{partition-number}.txt` files generated by the application instances.

#### Publisher

 * edit `.env` to configure the number of partitions and connection parameters
 * start the publishers: `./start-perf-test-partition.sh`
 * when you're done, stop the publishers: `./stop-all-perf-test.sh`

### Random Exchange

This workload uses RabbitMQ [random exchange](https://github.com/rabbitmq/rabbitmq-random-exchange)
This translates to using 1 exchange and using n queues. 
Note only 10 partitions at most are supported.

#### Broker

 * edit `.env` to configure the number of partitions
 * configure the AMQP resources: `./configure-broker.sh`
 * make sure the queue are empty: `./purge-queues-random.sh`

#### Consumer

 * edit `.env` to configure the number of partitions, connection parameters, and
 any consumer-related option (e.g. prefetch count)
 * start the Spring Cloud Stream application instances: `./start-scst-random.sh`
 * make sure all the instances are connected to the broker by e.g. looking at the
 management plugin (all instances can take some time to load when several partitions are used)
 * when you're done, stop the application instances: `./stop-all-scst.sh`

You can get consuming throughput numbers from the management plugin or from
`random-{partition-number}.txt` files generated by the application instances.

#### Publisher

 * edit `.env` to configure the number of partitions and connection parameters
 * start the publishers: `./start-perf-test-random.sh`
 * when you're done, stop the publishers: `./stop-all-perf-test.sh`
 
### Sharding Plugin

This workload uses RabbitMQ [sharding plugin](https://github.com/rabbitmq/rabbitmq-sharding)
This translates to using 1 exchange and SCST applications connecting to a sharded queue, which is
actually backed up by n queues. 
Note only 10 partitions at most are supported.

#### Broker

 * edit `.env` to configure the number of partitions
 * configure the AMQP resources: `./configure-broker.sh`
 * make sure the queue are empty: `./purge-queues-sharding.sh`

#### Consumer

 * edit `.env` to configure the number of partitions, connection parameters, and
 any consumer-related option (e.g. prefetch count)
 * start the Spring Cloud Stream application instances: `./start-scst-sharding.sh`
 * make sure all the instances are connected to the broker by e.g. looking at the
 management plugin (all instances can take some time to load when several partitions are used)
 * when you're done, stop the application instances: `./stop-all-scst.sh`

You can get consuming throughput numbers from the management plugin or from
`sharding-{partition-number}.txt` files generated by the application instances.

#### Publisher

 * edit `.env` to configure the number of partitions and connection parameters
 * start the publishers: `./start-perf-test-sharding.sh`
 * when you're done, stop the publishers: `./stop-all-perf-test.sh`
 
### Consistent Hash Exchange

This workload uses RabbitMQ [consistent hash exchange](https://github.com/rabbitmq/rabbitmq-consistent-hash-exchange)
This translates to using 1 exchange and SCST applications connecting to n queues. 
Note only 10 partitions at most are supported.

#### Broker

 * edit `.env` to configure the number of partitions
 * configure the AMQP resources: `./configure-broker.sh`
 * make sure the queue are empty: `./purge-queues-hash.sh`

#### Consumer

 * edit `.env` to configure the number of partitions, connection parameters, and
 any consumer-related option (e.g. prefetch count)
 * start the Spring Cloud Stream application instances: `./start-scst-hash.sh`
 * make sure all the instances are connected to the broker by e.g. looking at the
 management plugin (all instances can take some time to load when several partitions are used)
 * when you're done, stop the application instances: `./stop-all-scst.sh`

You can get consuming throughput numbers from the management plugin or from
`hash-{partition-number}.txt` files generated by the application instances.

#### Publisher

 * edit `.env` to configure the number of partitions and connection parameters
 * start the publishers: `./start-perf-test-hash.sh`
 * when you're done, stop the publishers: `./stop-all-perf-test.sh`